{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde03a41",
   "metadata": {},
   "source": [
    "## Querying and Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c4b7d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ebc999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging (Jupyter sets up it's own so we have to add ours instead of using a basicConfig)\n",
    "log = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "log.addHandler(fhandler)\n",
    "log.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbb62c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for performing a GET request using requests library with retries\n",
    "# Sets a 5 second timeout by default\n",
    "def get_request(url, parameters=None, timeout=5):\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters, timeout=timeout)\n",
    "    except SSLError as s:\n",
    "        log.error('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        log.warn('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recusively try again\n",
    "        return get_request(url, parameters)\n",
    "    \n",
    "    if response:\n",
    "        log.debug('Got response {0}'.format(response.status_code))\n",
    "        return response\n",
    "    else:\n",
    "        # response is none usually means too many requests. Wait and try again \n",
    "        log.warn('No response, waiting 10 seconds...')\n",
    "        time.sleep(10)\n",
    "        log.warn('Retrying.')\n",
    "        return get_request(url, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c9306db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries the games for a given username. To find your username, check your profile under General -> Custom URL\n",
    "def get_steam_xml(username):\n",
    "    if os.path.exists(\"steam_games.xml\"):\n",
    "        log.info('Steam XML is cached')\n",
    "        with open(\"steam_games.xml\", \"r\", encoding=\"utf-8\") as games_file:\n",
    "            contents = games_file.read()\n",
    "    else:\n",
    "        log.info('Steam XML needs query')\n",
    "        xml_url = 'http://steamcommunity.com/id/{0}/games?tab=all&xml=1'.format(username)\n",
    "        xml_contents = get_request(xml_url, timeout=5)\n",
    "        with open(\"steam_games.xml\", \"w\", encoding=\"utf-8\") as games_file:\n",
    "            games_file.write(xml_contents.text)\n",
    "\n",
    "        contents = xml_contents.text\n",
    "\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "478d4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the games XML returned from get_steam_xml() and outputs a pandas dataframe\n",
    "def get_game_info(username):\n",
    "    steam_xml = get_steam_xml(username)\n",
    "    tree = ET.ElementTree(ET.fromstring(steam_xml))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    if root.find('error') is not None:\n",
    "        log.error(root.find('error').text)\n",
    "        sys.exit(0)\n",
    "\n",
    "    game_infos = []\n",
    "    \n",
    "    for game in root.iter('game'):\n",
    "        app_id = game.find('appID').text\n",
    "        name = game.find('name').text\n",
    "        \n",
    "        propertyOrDefault = lambda name: (game.find(name).text) if (game.find(name) is not None) else np.nan\n",
    "\n",
    "        # Rest of these are optional\n",
    "        logo_link = propertyOrDefault('logo')    \n",
    "        store_link = propertyOrDefault('storeLink')\n",
    "        hours_last_2_weeks = float(propertyOrDefault('hoursLast2Weeks'))\n",
    "        hours_on_record = float(propertyOrDefault('hoursOnRecord'))\n",
    "        stats_link = propertyOrDefault('statsLink')\n",
    "        global_stats_link = propertyOrDefault('globalStatsLink')\n",
    "        \n",
    "        game_infos.append((app_id, name, logo_link, store_link, hours_last_2_weeks, hours_on_record,\n",
    "                           stats_link, global_stats_link))\n",
    "\n",
    "    df = pd.DataFrame.from_records(game_infos,\n",
    "                                   columns=['AppId', 'Name', 'LogoLink', 'StoreLink', 'HoursLast2Weeks',\n",
    "                                            'HoursOnRecord', 'StatsLink', 'GlobalStatsLink'])\n",
    "    df.set_index('AppId')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d592508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from SteamSpy for each game\n",
    "# The structure of game_infos must be at least two columns named 'AppId' and 'Name'.\n",
    "# Setting 'in_place' to true will modify the input game_infos preserving any other existing columns.\n",
    "# Otherwise, they are discarded.\n",
    "# pull_first_n allows limiting the number of queries to the first N found.\n",
    "def get_steamspy_data(cache_file, game_infos, pull_first_n = None, in_place = False):\n",
    "    cache = pd.DataFrame()\n",
    "    if os.path.exists(cache_file):\n",
    "        cache = pd.read_csv(cache_file, index_col = False)\n",
    "\n",
    "    final_names = []\n",
    "    final_appids = []\n",
    "    final_score_rank = []\n",
    "    final_positive = []\n",
    "    final_negative = []\n",
    "    final_total_ratings = []\n",
    "    final_ratings_ratio = []\n",
    "    final_user_score = []\n",
    "    final_avg_forever = []\n",
    "    final_avg_2weeks = []\n",
    "    final_med_forever = []\n",
    "    final_med_2weeks = []\n",
    "\n",
    "    pulled = 0\n",
    "    \n",
    "    for i, r in game_infos.iterrows():\n",
    "        name = r['Name']\n",
    "        appid = i\n",
    "\n",
    "        cache_found = False\n",
    "        if cache.empty == False:\n",
    "            log.info(\"Found {0} in cache\".format(name))\n",
    "            cache_row = cache.loc[cache['Name'] == name]\n",
    "            if cache_row.empty == False:\n",
    "                final_appids.append(appid)\n",
    "                final_names.append(name)\n",
    "                final_positive.append(int(cache_row[\"Positive\"]))\n",
    "                final_negative.append(int(cache_row[\"Negative\"]))\n",
    "                final_total_ratings.append(int(cache_row[\"TotalRatings\"]))\n",
    "                final_ratings_ratio.append(float(cache_row[\"RatingsRatio\"]))\n",
    "                final_user_score.append(int(cache_row[\"UserScore\"]))\n",
    "                final_avg_forever.append(int(cache_row[\"AvgForever\"]))\n",
    "                final_avg_2weeks.append(int(cache_row[\"Avg2Weeks\"]))\n",
    "                final_med_forever.append(int(cache_row[\"MedForever\"]))\n",
    "                final_med_2weeks.append(int(cache_row[\"Med2Weeks\"]))\n",
    "\n",
    "                cache_found = True\n",
    "\n",
    "        if cache_found == False:\n",
    "            log.info(\"Request {0} from SteamSpy\".format(name))\n",
    "                \n",
    "            url = \"http://steamspy.com/api.php\"\n",
    "            parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "            json_data = get_request(url, parameters=parameters).json()\n",
    "            game_info = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "            for game in game_info:\n",
    "                positive = json_data[\"positive\"]\n",
    "                negative = json_data[\"negative\"]\n",
    "                total_ratings = positive + negative\n",
    "                if total_ratings > 0:\n",
    "                    positive_percent = (positive / total_ratings) * 100\n",
    "                else:\n",
    "                    positive_percent = 0\n",
    "                user_score = json_data[\"userscore\"]\n",
    "                avg_forever = json_data[\"average_forever\"]\n",
    "                avg_2weeks = json_data[\"average_2weeks\"]\n",
    "                med_forever = json_data[\"median_forever\"]\n",
    "                med_2weeks = json_data[\"median_2weeks\"]            \n",
    "\n",
    "                log.debug(\"Finished request for {0}\".format(name))\n",
    "                final_appids.append(appid)\n",
    "                final_names.append(name)\n",
    "                final_positive.append(positive)\n",
    "                final_negative.append(negative)\n",
    "                final_total_ratings.append(total_ratings)\n",
    "                final_ratings_ratio.append(positive_percent)\n",
    "                final_user_score.append(user_score)\n",
    "                final_avg_forever.append(avg_forever)\n",
    "                final_avg_2weeks.append(avg_2weeks)\n",
    "                final_med_forever.append(med_forever)\n",
    "                final_med_2weeks.append(med_2weeks)\n",
    "\n",
    "                # Per documentation, don't make more than 1 request per second\n",
    "                time.sleep(2)\n",
    "        \n",
    "        pulled = pulled + 1\n",
    "        if pull_first_n is not None:\n",
    "            log.debug(\"Pulled {0} of {1}\".format(pulled, pull_first_n))\n",
    "            if pulled == pull_first_n:\n",
    "                break\n",
    "\n",
    "    if in_place == False:\n",
    "        log.info(\"Returning new data frame\")\n",
    "        df = pd.DataFrame(list(zip(final_appids,\n",
    "                                   final_names,\n",
    "                                   final_positive,\n",
    "                                   final_negative,\n",
    "                                   final_total_ratings,\n",
    "                                   final_ratings_ratio,\n",
    "                                   final_user_score,\n",
    "                                   final_avg_forever,\n",
    "                                   final_avg_2weeks,\n",
    "                                   final_med_forever,\n",
    "                                   final_med_2weeks)),\n",
    "                          columns = ['AppId',\n",
    "                                     'Name',\n",
    "                                     'Positive',\n",
    "                                     'Negative',\n",
    "                                     'TotalRatings',\n",
    "                                     'RatingsRatio',\n",
    "                                     'UserScore',\n",
    "                                     'AvgForever',\n",
    "                                     'Avg2Weeks',\n",
    "                                     'MedForever',\n",
    "                                     'Med2Weeks'\n",
    "                                    ])\n",
    "        df.to_csv(cache_file)\n",
    "        return df\n",
    "    else:\n",
    "        log.info(\"Appending columns to existing data frame\")\n",
    "        # Add the new columns to the existing game_infos\n",
    "        game_infos['Positive'] = final_positive\n",
    "        game_infos['Negative'] = final_negative\n",
    "        game_infos['TotalRatings'] = final_total_ratings\n",
    "        game_infos['RatingsRatio'] = final_ratings_ratio\n",
    "        game_infos['UserScore'] = final_user_score\n",
    "        game_infos['AvgForever'] = final_avg_forever\n",
    "        game_infos['Avg2Weeks'] = final_avg_2weeks\n",
    "        game_infos['MedForever'] = final_med_forever\n",
    "        game_infos['Med2Weeks'] = final_med_2weeks\n",
    "        \n",
    "        game_infos.to_csv(cache_file)\n",
    "        return game_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80202589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Bayesian average to better rank the games\n",
    "def p_calculate_bayesian_average(item_num_ratings, item_ratio_ratings,\n",
    "                system_avg_num_ratings, system_ratio_ratings):\n",
    "    b_avg = (((item_num_ratings) / (item_num_ratings + system_avg_num_ratings)) * item_ratio_ratings) + (((system_avg_num_ratings) /  (item_num_ratings + system_avg_num_ratings)) * system_ratio_ratings)\n",
    "    return b_avg\n",
    "\n",
    "def add_bayesian_average_to_gamespy_dataframe(steamspy_df):\n",
    "    # Calculate an overall average for the system\n",
    "    system_ratings_avg = steamspy_df[\"RatingsRatio\"].mean()\n",
    "    system_num_ratings_avg = steamspy_df[\"TotalRatings\"].mean()\n",
    "\n",
    "    # Calculate Bayesian average\n",
    "    b_averages = list(steamspy_df.apply(lambda row:\n",
    "        p_calculate_bayesian_average(row[\"TotalRatings\"], row[\"RatingsRatio\"],\n",
    "                    system_num_ratings_avg, system_ratings_avg), axis=1))\n",
    "\n",
    "    # Add the new averages to the data frame\n",
    "    steamspy_df['Bayesian'] = b_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8457bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, your 'Game details' must be set to 'Public' for this to work.\n",
    "# This is done in your profile -> Edit Profile -> Privacy Settings -> Game details\n",
    "# To find your username, check your profile under General -> Custom URL\n",
    "username = ''\n",
    "if username == '':\n",
    "    if os.path.exists(\"steam_id.dat\"):\n",
    "        log.info('Reading steam ID from file')\n",
    "        with open(\"steam_id.dat\", \"r\", encoding=\"utf-8\") as id_file:\n",
    "            username = id_file.read()\n",
    "    else:\n",
    "        log.critical('Need steam user ID')\n",
    "else:\n",
    "    # Note: get_game_info does not check if username matches in case the file is already cached.\n",
    "    game_infos = get_game_info(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a087c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorate our steam library info with ranking info from SteamSpy\n",
    "steamspy_data = get_steamspy_data(\"steam_spy_cache.csv\", game_infos, in_place = True)\n",
    "add_bayesian_average_to_gamespy_dataframe(steamspy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21dc4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any filtering or re-arranging you want to here\n",
    "steamspy_data = steamspy_data.sort_values(by=['Bayesian'], ascending=False)\n",
    "\n",
    "# Write to file for easy access\n",
    "steamspy_data.to_csv(\"bayesian.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1eb532",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11cbab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper\n",
    "from bokeh.palettes import Turbo256 as palette\n",
    "from bokeh.transform import linear_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe242cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot most played games (ignore non played games)\n",
    "\n",
    "colName = \"HoursOnRecord\"\n",
    "\n",
    "most_played_games = pd.DataFrame.copy(steamspy_data)\n",
    "most_played_games.dropna(axis = 0, subset = [colName], inplace = True)\n",
    "most_played_games = most_played_games.sort_values(by=[colName], ascending=False)\n",
    "most_played_games.tail()\n",
    "\n",
    "p = figure(x_range = most_played_games[\"Name\"], width = 2000, title = \"Most played games\")\n",
    "p.vbar(x = most_played_games[\"Name\"], top = most_played_games[colName], width = 0.5)\n",
    "p.xaxis.major_label_orientation = \"vertical\"\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7debacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot most played games in last 2 weeks\n",
    "\n",
    "colName = \"HoursLast2Weeks\"\n",
    "\n",
    "most_played_games_2w = pd.DataFrame.copy(steamspy_data)\n",
    "most_played_games_2w.dropna(axis = 0, subset = [colName], inplace = True)\n",
    "most_played_games_2w = most_played_games_2w.sort_values(by=[colName], ascending=False)\n",
    "most_played_games_2w.tail()\n",
    "\n",
    "p = figure(x_range = most_played_games_2w[\"Name\"], width = 2000, title = \"Most played games in last 2 weeks\")\n",
    "p.vbar(x = most_played_games_2w[\"Name\"], top = most_played_games_2w[colName], width = 0.5)\n",
    "p.xaxis.major_label_orientation = \"vertical\"\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a7f3c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot most played games versus their rating (ignore non played games)\n",
    "\n",
    "colName = \"HoursOnRecord\"\n",
    "\n",
    "most_played_games = pd.DataFrame.copy(steamspy_data)\n",
    "most_played_games.dropna(axis = 0, subset = [colName], inplace = True)\n",
    "most_played_games = most_played_games.sort_values(by=[colName], ascending=False)\n",
    "\n",
    "tooltips = [\n",
    "    ('Game', '@Name'),\n",
    "    ('Hours Played', '@HoursOnRecord'),\n",
    "    ('Rating', '@Bayesian')\n",
    "]\n",
    "\n",
    "color_mapper = linear_cmap(field_name = \"HoursOnRecord\",\n",
    "                           palette=palette,\n",
    "                           low=min(most_played_games[\"HoursOnRecord\"]),\n",
    "                           high=max(most_played_games[\"HoursOnRecord\"]))\n",
    "\n",
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'reset']\n",
    "\n",
    "data_source = ColumnDataSource(most_played_games)\n",
    "p = figure(plot_height = 1000,\n",
    "           plot_width = 2000,\n",
    "           title = \"Most played vs ranking\",\n",
    "           tools = select_tools)\n",
    "p.circle(x = \"HoursOnRecord\", y = \"Bayesian\",\n",
    "         color = color_mapper,\n",
    "         source = data_source,\n",
    "         selection_color = 'deepskyblue',\n",
    "         nonselection_color = 'lightgray', radius = 1)\n",
    "p.add_tools(HoverTool(tooltips=tooltips))\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ecd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
